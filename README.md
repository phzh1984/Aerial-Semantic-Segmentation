# Aerial-Semantic-Segmentation

Dataset Overview:

The Semantic Drone Dataset is designed to facilitate research in the field of semantic understanding of urban scenes with a focus on enhancing the safety of autonomous drone flight and landing procedures. This dataset offers imagery captured from a bird's eye view, showcasing more than 20 houses. The images were acquired at altitudes ranging from 5 to 30 meters above the ground using a high-resolution camera, resulting in images of 6000x4000 pixels (24 megapixels). The dataset is split into a training set comprising 400 publicly available images and a test set consisting of 200 private images.

Person Detection:

For tasks related to person detection, the dataset includes bounding box annotations for both the training and test sets.

Semantic Segmentation:

Pixel-accurate annotations have been prepared for the training and test sets for the task of semantic segmentation. The dataset features 20 distinct classes, each representing a specific type of object or terrain in the images. The classes are as follows:
tree

grass

other vegetation

dirt

gravel

rocks

water

paved area

pool

person

dog

car

bicycle

roof

wall

fence

fence-pole

window

door

obstacle

Additional Data Available:

In addition to the core dataset, several supplementary data types are available:

High-resolution images at a rate of 1Hz.

Fish-eye stereo images at 5Hz, synchronized with IMU measurements.

Thermal images at a rate of 1Hz.

Ground control points for georeferencing.

3D ground truth of 3 houses acquired using a total station.

Citation:

If you use this dataset in your research, please cite the following URL:

http://dronedataset.icg.tugraz.at


